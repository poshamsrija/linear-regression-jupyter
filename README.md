# linear-regression-jupyter
Implementation of Linear Regression from scratch in Python (Jupyter Notebook) using gradient descent.  Simple Linear Regression algorithm built from scratch with NumPy and Matplotlib. ML project: Linear Regression from scratch, trained via gradient descent and visualized in Jupyter Notebook.
# Linear Regression Model

## Description
This Jupyter Notebook implements **Linear Regression**, a supervised learning algorithm used for **predicting continuous values**. The notebook demonstrates:
- Training a linear regression model from scratch
- Calculating coefficients (slope and intercept)
- Making predictions and visualizing results with a graph

Linear Regression is widely used in **sales forecasting, price prediction, and trend analysis**.



## How It Works
The model predicts values using the formula:

\[
y = mX + b
\]

Where:
- \(y\) = predicted output
- \(m\) = slope of the line
- \(b\) = intercept
- \(X\) = input feature

The algorithm minimizes **Mean Squared Error (MSE)** to fit the best line.



## Requirements
- Python 3.x
- Jupyter Notebook
- Libraries: `numpy`, `matplotlib`, `pandas`


## Usage
1. Open `linear_regression.ipynb` in Jupyter Notebook.
2. Run all cells to train the model and visualize predictions.
3. Input your own dataset to test predictions.


